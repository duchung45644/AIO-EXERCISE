{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duchu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gdown\\__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu\n",
      "To: e:\\OneDrive\\OneDrive - nika04\\AIO-2024\\EXERCISE\\Module_5\\M5W3_16-11\\Auto_MPG_data.csv\n",
      "\n",
      "  0%|          | 0.00/15.4k [00:00<?, ?B/s]\n",
      "100%|██████████| 15.4k/15.4k [00:00<00:00, 15.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !gdown --id 1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'Auto_MPG_data.csv'\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['MPG']).values\n",
    "y = dataset['MPG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=val_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_val = normalizer.transform(X_val)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xây dựng DataLoader**: Để có thể duyệt qua bộ dữ liệu một cách hiệu quả cho việc huấn luyện cũng như đánh giá mô hình trong PyTorch, chúng ta cần xây dựng PyTorch DataLoader. Để xây dựng DataLoader, chúng ta cần phải xây dựng PyTorch Dataset nhằm lưu dữ liệu đầu vào đầu ra trong bài toán.\n",
    "Theo đó, ta sẽ xây dựng một PyTorch Dataset đơn giản như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val__dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val__dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self , input_dims , hidden_dims , output_dims):\n",
    "        super().__init__ ()\n",
    "        self.linear1 = nn.Linear(input_dims , hidden_dims)\n",
    "        self.linear2 = nn.Linear(hidden_dims , hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims , output_dims)\n",
    "\n",
    "    def forward(self , x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        out = self.output(x)\n",
    "        return out.squeeze (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train.shape[1]\n",
    "output_dims = 1\n",
    "hidden_dims = 64\n",
    "\n",
    "model = MLP(input_dims, hidden_dims, output_dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xây dựng hàm tính điểm R2**: Trong bài này, ta sẽ sử dụng thêm một độ đo khác cho bài regression là điểm R2 (Coefficient of determination). Cách triển khai như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true).to(device)\n",
    "    y_pred = torch.Tensor(y_pred).to(device)\n",
    "    mean_true = torch.mean(y_true)\n",
    "    ss_tot = torch.sum((y_true - mean_true) ** 2)\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:42: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:42: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\duchu\\AppData\\Local\\Temp\\ipykernel_10588\\1551046526.py:42: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f'\\nEPOCH {epoch + 1}:\\ tTraining loss: {train_loss :.3f}\\tValidation loss: {val_loss :.3f}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\\ tTraining loss: 3.744\tValidation loss: 5.620\n",
      "\n",
      "EPOCH 2:\\ tTraining loss: 5.727\tValidation loss: 10.227\n",
      "\n",
      "EPOCH 3:\\ tTraining loss: 5.229\tValidation loss: 5.636\n",
      "\n",
      "EPOCH 4:\\ tTraining loss: 3.826\tValidation loss: 9.930\n",
      "\n",
      "EPOCH 5:\\ tTraining loss: 3.757\tValidation loss: 5.912\n",
      "\n",
      "EPOCH 6:\\ tTraining loss: 5.184\tValidation loss: 7.872\n",
      "\n",
      "EPOCH 7:\\ tTraining loss: 7.393\tValidation loss: 9.833\n",
      "\n",
      "EPOCH 8:\\ tTraining loss: 6.764\tValidation loss: 5.360\n",
      "\n",
      "EPOCH 9:\\ tTraining loss: 6.415\tValidation loss: 6.718\n",
      "\n",
      "EPOCH 10:\\ tTraining loss: 4.979\tValidation loss: 8.645\n",
      "\n",
      "EPOCH 11:\\ tTraining loss: 4.285\tValidation loss: 5.904\n",
      "\n",
      "EPOCH 12:\\ tTraining loss: 4.068\tValidation loss: 6.247\n",
      "\n",
      "EPOCH 13:\\ tTraining loss: 3.796\tValidation loss: 6.102\n",
      "\n",
      "EPOCH 14:\\ tTraining loss: 3.880\tValidation loss: 4.599\n",
      "\n",
      "EPOCH 15:\\ tTraining loss: 5.792\tValidation loss: 5.963\n",
      "\n",
      "EPOCH 16:\\ tTraining loss: 4.200\tValidation loss: 6.659\n",
      "\n",
      "EPOCH 17:\\ tTraining loss: 4.987\tValidation loss: 6.151\n",
      "\n",
      "EPOCH 18:\\ tTraining loss: 4.254\tValidation loss: 6.180\n",
      "\n",
      "EPOCH 19:\\ tTraining loss: 4.120\tValidation loss: 5.858\n",
      "\n",
      "EPOCH 20:\\ tTraining loss: 3.877\tValidation loss: 5.514\n",
      "\n",
      "EPOCH 21:\\ tTraining loss: 3.761\tValidation loss: 6.746\n",
      "\n",
      "EPOCH 22:\\ tTraining loss: 3.773\tValidation loss: 9.348\n",
      "\n",
      "EPOCH 23:\\ tTraining loss: 3.949\tValidation loss: 8.752\n",
      "\n",
      "EPOCH 24:\\ tTraining loss: 6.867\tValidation loss: 6.761\n",
      "\n",
      "EPOCH 25:\\ tTraining loss: 4.282\tValidation loss: 6.361\n",
      "\n",
      "EPOCH 26:\\ tTraining loss: 4.051\tValidation loss: 5.572\n",
      "\n",
      "EPOCH 27:\\ tTraining loss: 5.691\tValidation loss: 8.814\n",
      "\n",
      "EPOCH 28:\\ tTraining loss: 4.094\tValidation loss: 5.634\n",
      "\n",
      "EPOCH 29:\\ tTraining loss: 4.615\tValidation loss: 8.785\n",
      "\n",
      "EPOCH 30:\\ tTraining loss: 4.230\tValidation loss: 5.467\n",
      "\n",
      "EPOCH 31:\\ tTraining loss: 3.545\tValidation loss: 8.626\n",
      "\n",
      "EPOCH 32:\\ tTraining loss: 3.479\tValidation loss: 5.690\n",
      "\n",
      "EPOCH 33:\\ tTraining loss: 4.552\tValidation loss: 8.071\n",
      "\n",
      "EPOCH 34:\\ tTraining loss: 4.841\tValidation loss: 5.913\n",
      "\n",
      "EPOCH 35:\\ tTraining loss: 4.892\tValidation loss: 7.619\n",
      "\n",
      "EPOCH 36:\\ tTraining loss: 5.240\tValidation loss: 10.129\n",
      "\n",
      "EPOCH 37:\\ tTraining loss: 4.819\tValidation loss: 7.291\n",
      "\n",
      "EPOCH 38:\\ tTraining loss: 3.708\tValidation loss: 6.156\n",
      "\n",
      "EPOCH 39:\\ tTraining loss: 3.766\tValidation loss: 8.862\n",
      "\n",
      "EPOCH 40:\\ tTraining loss: 3.861\tValidation loss: 6.999\n",
      "\n",
      "EPOCH 41:\\ tTraining loss: 3.282\tValidation loss: 5.913\n",
      "\n",
      "EPOCH 42:\\ tTraining loss: 3.409\tValidation loss: 6.011\n",
      "\n",
      "EPOCH 43:\\ tTraining loss: 3.739\tValidation loss: 5.844\n",
      "\n",
      "EPOCH 44:\\ tTraining loss: 3.361\tValidation loss: 5.285\n",
      "\n",
      "EPOCH 45:\\ tTraining loss: 3.750\tValidation loss: 9.267\n",
      "\n",
      "EPOCH 46:\\ tTraining loss: 4.041\tValidation loss: 5.772\n",
      "\n",
      "EPOCH 47:\\ tTraining loss: 4.091\tValidation loss: 6.956\n",
      "\n",
      "EPOCH 48:\\ tTraining loss: 3.723\tValidation loss: 6.642\n",
      "\n",
      "EPOCH 49:\\ tTraining loss: 4.936\tValidation loss: 6.687\n",
      "\n",
      "EPOCH 50:\\ tTraining loss: 4.431\tValidation loss: 5.891\n",
      "\n",
      "EPOCH 51:\\ tTraining loss: 4.325\tValidation loss: 7.457\n",
      "\n",
      "EPOCH 52:\\ tTraining loss: 3.563\tValidation loss: 7.609\n",
      "\n",
      "EPOCH 53:\\ tTraining loss: 3.598\tValidation loss: 5.930\n",
      "\n",
      "EPOCH 54:\\ tTraining loss: 4.049\tValidation loss: 7.413\n",
      "\n",
      "EPOCH 55:\\ tTraining loss: 3.828\tValidation loss: 5.318\n",
      "\n",
      "EPOCH 56:\\ tTraining loss: 4.068\tValidation loss: 16.296\n",
      "\n",
      "EPOCH 57:\\ tTraining loss: 5.570\tValidation loss: 7.420\n",
      "\n",
      "EPOCH 58:\\ tTraining loss: 3.330\tValidation loss: 8.154\n",
      "\n",
      "EPOCH 59:\\ tTraining loss: 3.875\tValidation loss: 11.902\n",
      "\n",
      "EPOCH 60:\\ tTraining loss: 6.280\tValidation loss: 7.801\n",
      "\n",
      "EPOCH 61:\\ tTraining loss: 3.261\tValidation loss: 6.518\n",
      "\n",
      "EPOCH 62:\\ tTraining loss: 6.517\tValidation loss: 6.296\n",
      "\n",
      "EPOCH 63:\\ tTraining loss: 4.121\tValidation loss: 6.536\n",
      "\n",
      "EPOCH 64:\\ tTraining loss: 3.698\tValidation loss: 5.889\n",
      "\n",
      "EPOCH 65:\\ tTraining loss: 3.675\tValidation loss: 7.482\n",
      "\n",
      "EPOCH 66:\\ tTraining loss: 3.764\tValidation loss: 10.379\n",
      "\n",
      "EPOCH 67:\\ tTraining loss: 6.153\tValidation loss: 10.957\n",
      "\n",
      "EPOCH 68:\\ tTraining loss: 8.639\tValidation loss: 7.316\n",
      "\n",
      "EPOCH 69:\\ tTraining loss: 3.740\tValidation loss: 6.475\n",
      "\n",
      "EPOCH 70:\\ tTraining loss: 4.503\tValidation loss: 6.413\n",
      "\n",
      "EPOCH 71:\\ tTraining loss: 3.452\tValidation loss: 5.898\n",
      "\n",
      "EPOCH 72:\\ tTraining loss: 3.318\tValidation loss: 7.662\n",
      "\n",
      "EPOCH 73:\\ tTraining loss: 3.846\tValidation loss: 6.798\n",
      "\n",
      "EPOCH 74:\\ tTraining loss: 3.915\tValidation loss: 7.135\n",
      "\n",
      "EPOCH 75:\\ tTraining loss: 3.034\tValidation loss: 5.810\n",
      "\n",
      "EPOCH 76:\\ tTraining loss: 3.566\tValidation loss: 5.326\n",
      "\n",
      "EPOCH 77:\\ tTraining loss: 3.416\tValidation loss: 5.901\n",
      "\n",
      "EPOCH 78:\\ tTraining loss: 3.011\tValidation loss: 5.810\n",
      "\n",
      "EPOCH 79:\\ tTraining loss: 3.126\tValidation loss: 6.062\n",
      "\n",
      "EPOCH 80:\\ tTraining loss: 5.309\tValidation loss: 6.867\n",
      "\n",
      "EPOCH 81:\\ tTraining loss: 3.532\tValidation loss: 5.955\n",
      "\n",
      "EPOCH 82:\\ tTraining loss: 4.459\tValidation loss: 7.534\n",
      "\n",
      "EPOCH 83:\\ tTraining loss: 3.423\tValidation loss: 5.669\n",
      "\n",
      "EPOCH 84:\\ tTraining loss: 3.069\tValidation loss: 5.515\n",
      "\n",
      "EPOCH 85:\\ tTraining loss: 3.089\tValidation loss: 6.341\n",
      "\n",
      "EPOCH 86:\\ tTraining loss: 3.124\tValidation loss: 12.100\n",
      "\n",
      "EPOCH 87:\\ tTraining loss: 4.309\tValidation loss: 8.551\n",
      "\n",
      "EPOCH 88:\\ tTraining loss: 5.676\tValidation loss: 8.899\n",
      "\n",
      "EPOCH 89:\\ tTraining loss: 6.105\tValidation loss: 6.337\n",
      "\n",
      "EPOCH 90:\\ tTraining loss: 4.067\tValidation loss: 7.230\n",
      "\n",
      "EPOCH 91:\\ tTraining loss: 3.452\tValidation loss: 7.107\n",
      "\n",
      "EPOCH 92:\\ tTraining loss: 3.956\tValidation loss: 6.573\n",
      "\n",
      "EPOCH 93:\\ tTraining loss: 4.136\tValidation loss: 6.639\n",
      "\n",
      "EPOCH 94:\\ tTraining loss: 3.215\tValidation loss: 6.039\n",
      "\n",
      "EPOCH 95:\\ tTraining loss: 3.922\tValidation loss: 5.978\n",
      "\n",
      "EPOCH 96:\\ tTraining loss: 3.430\tValidation loss: 6.766\n",
      "\n",
      "EPOCH 97:\\ tTraining loss: 3.243\tValidation loss: 9.481\n",
      "\n",
      "EPOCH 98:\\ tTraining loss: 2.920\tValidation loss: 6.198\n",
      "\n",
      "EPOCH 99:\\ tTraining loss: 3.672\tValidation loss: 6.632\n",
      "\n",
      "EPOCH 100:\\ tTraining loss: 4.333\tValidation loss: 6.616\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_target = []\n",
    "    val_target = []\n",
    "    train_predict = []\n",
    "    val_predict = []\n",
    "    model.train()\n",
    "    for X_samples , y_samples in train_loader:\n",
    "        X_samples = X_samples.to(device)\n",
    "        y_samples = y_samples.to(device)\n",
    "        optimizer.zero_grad ()\n",
    "        outputs = model(X_samples)\n",
    "        train_predict += outputs.tolist ()\n",
    "        train_target += y_samples.tolist ()\n",
    "        loss = criterion(outputs , y_samples)\n",
    "        loss.backward ()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_r2.append(r_squared(train_target , train_predict))\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad ():\n",
    "        for X_samples , y_samples in val_loader:\n",
    "            X_samples = X_samples.to(device)\n",
    "            y_samples = y_samples.to(device)\n",
    "            outputs = model(X_samples)\n",
    "            val_predict += outputs.tolist ()\n",
    "            val_target += y_samples.tolist ()\n",
    "            loss = criterion(outputs , y_samples)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_r2.append(r_squared(val_target , val_predict))\n",
    "    print(f'\\nEPOCH {epoch + 1}:\\ tTraining loss: {train_loss :.3f}\\tValidation loss: {val_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set:\n",
      "R2: 0.8796141147613525\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad ():\n",
    "    y_hat = model(X_test)\n",
    "    test_set_r2 = r_squared(y_hat , y_test)\n",
    "    print('Evaluation on test set:')\n",
    "    print(f'R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
